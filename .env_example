# AI Provider Configuration
# Compatible with OpenAI, DeepSeek, generic OpenAI-compatible APIs
AI_BASE_URL=https://api.openai.com/v1
AI_API_KEY=your_api_key_here

# Model Selection
# L1: Fast/Cheap model for initial screening (e.g., gpt-4o-mini, deepseek-chat)
AI_MODEL_L1=gpt-4o-mini
# L2: Smarter model for scoring and summarization (e.g., gpt-4o, deepseek-reasoner)
AI_MODEL_L2=gpt-4o

# Batch Processing Settings
# Increase these to handle higher news volume, decrease if hitting rate limits
L1_BATCH_SIZE=30        # How many news items to send to AI in one L1 batch
L2_BATCH_SIZE=20        # How many high-score items to send to L2 scoring in one batch

# Ranking Settings
GRAVITY=1.1             # Time decay factor. 1.8=Strong decay (Freshness), 0.8=Weak decay (Absolute Hotness)
RANKING_WINDOW_HOURS=72 # How many hours of news to include in the ranking list

# Proxy Settings (Optional)
# HTTP_PROXY=http://127.0.0.1:7890
# HTTPS_PROXY=http://127.0.0.1:7890

# RSS Feeds (JSON Array)
RSS_FEEDS='["https://spaceflightnow.com/feed/", "https://hnrss.org/newest?points=100"]'

